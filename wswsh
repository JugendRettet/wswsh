#!/usr/bin/mksh
# 2013 - wswsh - Ypnose <linuxien[AT]legtux[DOT]org
# wswsh

# Copyright (c) 2013, Ypnose - All rights reserved.
# This project is under BSD (3-Clause) License
# See LICENSE for license details.
#set -x
RAC="$1"

function usage {
	print "usage: wswsh [website_root]"
}

function parse_config {
	if [[ -r ${RAC}/wswsh.conf ]]; then
		. "${RAC}/wswsh.conf"
	else
		print -u2 "Missing configs"
		exit 1
	fi
}

function verify_dirs {
	if [[ ! -d ${RAC}/src ]]; then
		print -u2 "src doesn't exist"
		exit 1
	fi
	[[ ! -d ${RAC}/dest ]] && mkdir "${RAC}/dest"
}

function get_structure {
	# Add a fuckin' message?
	verify_dirs
	if [[ -n $(find "${RAC}/src" -type d -print) ]]; then
		# The following line works with GNU find:
		# find "${RAC}/src" -type d -printf "dest/%P\0" | xargs -0 mkdir -p
		# I finally decided to write lines "compatible" with {Mir,Open}BSD. Here we go:
		cd "${RAC}/dest"
		( cd ../src; find . -type d -print0 ) | xargs -0 mkdir -p
		cd ..
	else
		print "No directory found. Nothing to create"
	fi
}

function parse_css_f {
	if [[ -n $CSSF && -r ${RAC}/src/${CSSF} ]]; then
		CSSV=1
		print "Using custom CSS style"
		cp "${RAC}/src/${CSSF}" "${RAC}/dest/${CSSF}"
	fi
}

function do_backup {
	if [[ -n $BACKUP ]]; then
		if [[ -d $BACKUP ]]; then
			WHEN="$(date "+%Y-%m-%d")"
			rm -R "${BACKUP}/src_"*
			cp -R "${RAC}/src" "${BACKUP}/src_${WHEN}"
			
				cp "${RAC}/wswsh" "${BACKUP}/wswsh"
				cp "${RAC}/wswsh.conf" "${BACKUP}/wswsh.conf"
			
		else
			print -u2 "Directory doesn't exist!"
		fi
	fi
}

# Generate the page
function gen_page_skel {
	parse_css_f
	PAGES="$(find "${RAC}/src" -type f -iname "*.${EXT:-txt}")"
	print "Generating pages..."
	cd "$RAC"
	for f in $(find src -type f -iname "*.${EXT:-txt}"); do
		FILENOSRC="${f#*/}"
		FILENOEXT="${FILENOSRC%%.*}"
		FILEXPORT="dest/${FILENOEXT}.html"
		# We got the title from <h1>.
		ATIT="$(awk '/<h1>/{gsub(/\t/,"");gsub(/[</]|h1>/,"");gsub(/>|</,"");print " | "$0;exit}' $f)"
		page_head > "$FILEXPORT"
		"${INTERP:-cat}" $f >> "$FILEXPORT"
		page_foot >> "$FILEXPORT"
		RET=$?
		if (( RET != 0 )); then
			print -u2 "Generating $f failed"
			exit 1
		fi
	done

	# RSS / Atom
	if [[ -n $FEED && $FEED = @([Yy]es|YES) ]]; then
		# XML date, emulates $(date --rfc-3339=seconds) from GNU date.
		RDAT=$(LC_ALL=C date "+%Y-%m-%dT%H:%M:%SZ")
		RSSF="dest/${RSSDIR}atom.xml"
		gen_site_xml > "$RSSF"
		for z in $(find "src/blog/" -mindepth 2 -type f -iname "*.${EXT:-txt}"); do
			# Don't need to enable a specific hour, let's assume I wrote the pages at midnight.
			RDADAT="$(awk '/<!--/{gsub(/\t/,"");gsub(/<!-- | -->/,"");print $0"T00:00:00Z";exit}' $z)"
			RSSDES="$(awk '/<!-- DESC: /{gsub(/\t/,"");gsub(/<!-- DESC: | -->/,"");print $0;exit}' $z)"
			RSSTIT="$(awk '/<h1>/{gsub(/\t/,"");gsub(/[</]|h1>/,"");gsub(/>|</,"");print $0;exit}' $z)"
			RSSTNOSRC="${z#*/}"
			RSSTNOEXT="${RSSTNOSRC%%.*}"
			xml_content >> "$RSSF"
		done
		print '</feed>' >> "$RSSF"
	fi

	# We copy existing *.html files from src to dest.
	for x in $(find "src" -type f -iname "*.html"); do
		if [[ -r dest/${x#*/} ]]; then
			print "dest/${x#*/} already exists"
			continue
		fi
		cp "$x" "dest/${x#*/}"
	done

	# Test if the file exists. Then find it/them and copy it/them to dest (supports multiple files with same name).
	if [[ -n $FIL ]]; then
		for y in $FIL; do
			if [[ -z $(find "src" -type f -name "$y") ]]; then
				print "$y is missing"
				continue
			fi
			for c in $(find "src" -type f -name "$y"); do
				cp "src/${c#*/}" "dest/${c#*/}"
			done
		done
	fi

	cd ..
	TOT=$(find "${RAC}/dest" -type f | wc -l)
	print "Generated $TOT files."
}

# Page content
function page_head {
	print '<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8" />
	<meta name="author" content="John Foo" />'
	(( CSSV == 1 )) && print "	<link rel=\"stylesheet\" type=\"text/css\" href=\"/${CSSF}\" />"
	[[ -n $WTIT ]] && print "	<title>${WTIT}${ATIT}</title>"
	print '</head>
<body>
	<div>FOO</div>'
}

function page_foot {
	print '	<!-- Page generated by wswsh - '"$(LC_ALL=C date)"' -->
</body>
</html>'
}

function gen_site_xml {
	print '<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

	<title>'"${WTIT}"'</title>
	<link href="http://'${WURL}'/"/>
	<link type="application/atom+xml" rel="self" href="http://'${WURL}'/'${RSSDIR}'atom.xml"/>
	<updated>'"${RDAT}"'</updated>
	<author>
		<name>My_awesome_name</name>
	</author>
	<id>http://'"${WURL}"'/</id>
'
}

function xml_content {
	print '	<entry>
		<title>'"${RSSTIT}"'</title>
		<link href="http://'${WURL}'/'${RSSTNOEXT}'.html"/>
		<id>http://'"${WURL}"'/'"${RSSTNOEXT}"'.html</id>
		<updated>'"${RDADAT}"'</updated>
		<summary>'"${RSSDES}"'</summary>
	 </entry>
'
}

if [[ -z $1 ]]; then
	usage
	exit 1
fi

parse_config
get_structure
gen_page_skel
do_backup

exit 0
